#!/usr/bin/env python3

import peggy
import argparse
import json
import sys
import pprint

EscapeChar = {
    'a': '\a',
    'b': '\b',
    'f': '\f',
    'n': '\n',
    'r': '\r',
    't': '\t',
    'v': '\v',
    '\\': '\\',
    '"': '"',
    '\'': '\'',
    '-': '-'
}


def parse_range(s):
	r = ''
	l = len(s)
	i = 0
	while i < l:
		if s[i] == '\\':
			if i < l - 1 and s[i + 1] in EscapeChar:
				r += EscapeChar[s[i + 1]]
				i += 1
			elif i < l - 1 and s[i + 1] == ']':
				r += ']'
				i += 1
			else:
				return None
		elif s[i] == '-' and i > 0 and i < l - 1:
			r += ''.join(
			    [chr(o) for o in range(ord(s[i - 1]) + 1,
			                           ord(s[i + 1]) + 1)]
			)
			i += 1
		else:
			r += s[i]
		i += 1
	return r


def waxeyePrepare(node):
	assert (ast['step']['type'] == 'CALL' and ast['step']['data'] == 'Grammar')
	for definition in ast['children']:
		assert (
		    definition['step']['type'] == 'CALL'
		    and definition['step']['data'] == 'Definition'
		    and len(definition['children']) == 3
		)
		identifier = definition['children'][0]
		assert (
		    identifier['step']['type'] == 'CALL'
		    and identifier['step']['data'] == 'Identifier'
		)
		waxeyeSimplify(definition['children'][2])


def waxeyeUnit2json(ast, data):
	unit = {'ast': 'BUILD'}
	prefix = ''
	if ast['children'][0]['step']['type'] == 'CALL' and ast['children'][0][
	    'step']['data'] == 'Prefix':
		prefix = peggy.astdata(ast['children'][0], data)
		ast['children'].pop(0)

	if ast['children'][0]['step']['type'] == 'CALL' and ast['children'][0][
	    'step']['data'] == 'Literal':
		unit['type'] = 'STRING'
		unit['data'] = peggy.astdata(
		    ast['children'][0], data
		).strip()[1:-1].encode('utf-8').decode('unicode_escape')
	elif ast['children'][0]['step']['type'] == 'CALL' and ast['children'][0][
	    'step']['data'] == 'CaseLiteral':
		unit['type'] = 'STRING'
		unit['data'] = peggy.astdata(
		    ast['children'][0], data
		).strip()[1:-1].encode('utf-8').decode('unicode_escape')
	elif ast['children'][0]['step']['type'] == 'CALL' and ast['children'][0][
	    'step']['data'] == 'Identifier':
		unit['type'] = 'CALL'
		unit['data'] = peggy.astdata(ast['children'][0],
		                             data).strip().split()[0]
	elif ast['children'][0]['step']['type'] == 'CALL' and ast['children'][0][
	    'step']['data'] == 'CharClass':
		unit['type'] = 'RANGE'
		unit['data'] = parse_range(
		    peggy.astdata(ast['children'][0], data).strip()[1:-1]
		)
	elif ast['children'][0]['step']['type'] == 'CALL' and ast['children'][0][
	    'step']['data'] == 'WildCard':
		unit['type'] = 'WILDCARD'
	else:
		unit = waxeyeNode2json(ast['children'][0], data)

	if prefix:
		if prefix == '*':
			unit['min'] = 0
			unit['max'] = sys.maxsize
		elif prefix == '+':
			unit['min'] = 1
			unit['max'] = sys.maxsize
		elif prefix == '?':
			unit['min'] = 0
			unit['max'] = 1
		elif prefix == '&':
			unit['predicate'] = True
			unit['ast'] = 'VOID'
		elif prefix == '!':
			unit['predicate'] = False
			unit['ast'] = 'VOID'
		elif prefix == ':':
			unit['ast'] = 'VOID'
		else:
			raise NotImplementedError(
			    'prefix {} not implemented'.format(prefix)
			)

	return unit


def waxeyeSequence2json(ast, data):
	assert (len(ast['children']) > 0)

	if len(ast['children']) == 1:
		return waxeyeNode2json(ast['children'][0], data)

	node = {
	    'type': 'SEQUENCE',
	    'data': [],
	    'ast': "SKIP",
	}
	for child in ast['children']:
		node['data'].append(waxeyeNode2json(child, data))
	return node


def waxeyeAlternation2json(ast, data):
	assert (len(ast['children']) > 0)

	if len(ast['children']) == 1:
		return waxeyeNode2json(ast['children'][0], data)

	a = {
	    'type': 'CHOICE',
	    'data': [],
	    'ast': "SKIP",
	}
	for i in range(0, len(ast['children'])):
		a['data'].append(waxeyeNode2json(ast['children'][i], data))
	return a


def waxeyeNode2json(node, data):
	if node['step']['type'] == 'CALL':
		if node['step']['data'] == 'Alternation':
			return waxeyeAlternation2json(node, data)
		elif node['step']['data'] == 'Sequence':
			return waxeyeSequence2json(node, data)
		elif node['step']['data'] == 'Unit':
			return waxeyeUnit2json(node, data)
		else:
			raise NotImplementedError(
			    'Unknown rule {}'.format(node['step']['data'])
			)
	raise RuntimeError('Unknown step: {}'.format(node['step']))


def waxeyeGrammar2json(ast, data):
	g = {}
	assert (ast['step']['type'] == 'CALL' and ast['step']['data'] == 'Grammar')
	for definition in ast['children']:
		assert (definition['step']['type'] == 'CALL')
		assert (definition['step']['data'] == 'Definition')
		assert (len(definition['children']) == 3)
		identifier = definition['children'][0]
		assert (
		    identifier['step']['type'] == 'CALL'
		    and identifier['step']['data'] == 'Identifier'
		)
		arrow = definition['children'][1]
		#print(peggy.astdata(identifier,data),peggy.astdata(arrow,data))
		assert (arrow['step']['type'] == 'CALL')
		rule = peggy.astdata(identifier, data).strip().split()[0]
		g[rule] = {
		    'type': 'RULE',
		    'ast': {
		        'LeftArrow': 'BUILD',
		        'VoidArrow': 'VOID'
		    }[arrow['step']['data']],
		    'data': waxeyeNode2json(definition['children'][2], data),
		}
	return g


grammars = {
    'waxeye': {
        'tree': json.load(open('grammars/waxeye.json')),
        'rule': 'Grammar',
        'transform': waxeyeGrammar2json,
    },
}

parser = argparse.ArgumentParser(description = 'Peggy grammar converter')
parser.add_argument(
    'input',
    type = str,
    choices = grammars.keys(),
    help = 'Grammar input format'
)
parser.add_argument('grammar', type = open, help = 'Grammar input file')
parser.add_argument(
    'output',
    type = lambda s: open(s, 'w+'),
    default = sys.stdout,
    nargs = '?'
)
parser.add_argument('-d', '--debug', action = 'store_true', default = False)
args = parser.parse_args()

data = args.grammar.read()

pparser = peggy.Peggy(grammars[args.input]['tree'])
ast = pparser.parse(data, grammars[args.input]['rule'], debug = args.debug)

if ast['error'] is True:
	raise RuntimeError(
	    'Could not parse input grammar with {} format'.format(args.input)
	)
elif ast['length'] < len(data):
	raise RuntimeError(
	    'Could only parse {} of {} bytes of input grammar with {} format'.
	    format(ast['length'], len(data), args.input)
	)
peggy.astprint(ast['nodes'][0], data)
args.output.write(
    json.dumps(
        grammars[args.input]['transform'](ast['nodes'][0], data),
        indent = 2,
        sort_keys = True
    )
)
